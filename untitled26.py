# -*- coding: utf-8 -*-
"""Untitled26.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13PBWxpxsI0cTG9Wl76a5V24oPwCzSkwu
"""

import numpy as np
import pandas as pd

df = pd.read_csv('heart.csv')

df.head()

df.info()

df.describe()

df.isnull().sum()

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

sns.countplot(x='HeartDisease', data=df)
sns.heatmap(df.corr(),annot=True,cmap='coolwarm')

x = df.drop('HeartDisease',axis=1)
y = df['HeartDisease']

X = pd.get_dummies(x, columns=['Sex','ChestPainType','RestingECG','ExerciseAngina','ST_Slope'],drop_first=True)

scaler = StandardScaler()

X_scaled = scaler.fit_transform(X)

from sklearn.model_selection import  train_test_split
X_train,X_test,y_train,y_test = train_test_split(X_scaled,y,test_size=0.2,random_state=42)

rf = RandomForestClassifier()

rf.fit(X_train,y_train)

y_pred = rf.predict(X_test)

print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score,roc_auc_score

models = {
    'LogisticRegression': LogisticRegression(max_iter=1000),
    'KNeighborsClassifier': KNeighborsClassifier(),
    'SVC': SVC()
}
results =[]
for name,model in models.items():
    model.fit(X_train,y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test,y_pred)
    roc_auc = roc_auc_score(y_test,y_pred)
    results.append({
        'Model': name,
        'Accuracy': round(accuracy, 4),
        'ROC-AUC': round(roc_auc, 4)
    })

results_df = pd.DataFrame(results)
print(results_df)

print(results_df.columns)

sns.barplot(data=results_df.melt(id_vars='Model'), x='Model', y='value', hue='variable')
plt.title('Model Performance Comparison')
plt.ylabel('Score')
plt.xticks(rotation=20)
plt.show()

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, roc_auc_score
from xgboost import XGBClassifier

rf = RandomForestClassifier(random_state=42)
xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)

rf.fit(X_train,y_train)
xgb.fit(X_train,y_train)

rf_pred = rf.predict(X_test)
xgb_pred = xgb.predict(X_test)

rf_probs = rf.predict_proba(X_test)[:,1]
xgb_probs = xgb.predict_proba(X_test)[:,1]

rf_accuracy = accuracy_score(y_test,rf_pred)
xgb_accuracy = accuracy_score(y_test,xgb_pred)

rf_auc = roc_auc_score(y_test,rf_probs)
xgb_auc = roc_auc_score(y_test,xgb_probs)

new_results = pd.DataFrame({
    'Model': ['Random Forest', 'XGBoost'],
    'Accuracy': [rf_accuracy, xgb_accuracy],
    'ROC-AUC': [rf_auc, xgb_auc]
})

# Combine with previous results
results_df = pd.concat([results_df, new_results], ignore_index=True)
print(results_df)

from sklearn.model_selection import cross_val_score

models = {
    "Logistic Regression": LogisticRegression(),
    "K nearest neighbors": KNeighborsClassifier(),
    "SVM": SVC(probability=True),
    "Random Forest": RandomForestClassifier(random_state=42),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
}

cv_results = []

for name, model in models.items():
    acc_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')
    auc_scores = cross_val_score(model, X, y, cv=5, scoring='roc_auc')

    cv_results.append({
        'Model': name,
        'Accuracy': acc_scores.mean(),
        'ROC-AUC': auc_scores.mean()
    })

# Create DataFrame
results_df = pd.DataFrame(cv_results)
print(results_df)

from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))

for name, model in models.items():
    model.fit(X_train, y_train)
    y_prob = model.predict_proba(X_test)[:, 1]  # Probabilities for ROC curve
    fpr, tpr, _ = roc_curve(y_test, y_prob)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve Comparison')
plt.legend()
plt.grid()
plt.show()

import joblib

# Save model
joblib.dump(xgb, 'heart_disease_model.pkl')

# To load it later
# model = joblib.load('heart_disease_model.pkl')

pip install streamlit

# app.py
import streamlit as st
import joblib
import numpy as np

model = joblib.load('heart_disease_model.pkl')

st.title("Heart Disease Predictor")

# Example inputs
age = st.number_input("Age", 20, 100)
chol = st.number_input("Cholesterol", 100, 400)
sex = st.selectbox("Sex", ['M', 'F'])

# Add more features...

if st.button("Predict"):
    # Dummy encoding, update this based on your actual model input
    X_new = np.array([[age, chol, 1 if sex == 'M' else 0, ...]])
    pred = model.predict(X_new)
    st.success("Heart Disease Risk: " + ("Yes" if pred[0] == 1 else "No"))

streamlit run app.py

